---
title: "p8105_hw2_dm3175"
author: "Devon Morgan"
date: "9/26/2018"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(p8105.datasets)
library("dplyr")
library(readxl)
```

# Problem 1: NYC Transit Data
Problem 1 will use NYC Transit Data which includes information on entrance and exits for all subway stations located in New York City. 

## Import and Clean Dataset
The dataset was first imported and cleaned: 

```{r import nyc transit data}
NYC_traffic_data = read_csv(file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
                            col_types = "cccddccccccccccccccccclclcccddcc") %>% 
  janitor::clean_names() %>% 
  select(line, station_name, station_latitude, station_longitude, 
       route1:route11, entry, vending, entrance_type, ada) %>% 
  mutate(entry = recode(entry, 'YES' = "TRUE", 'NO' = "FALSE")) %>% 
  mutate(entry = as.logical(entry),
          entrance_type = tolower(entrance_type),
          line = tolower(line),
          station_name = tolower(station_name))
```

## Description of Dataset
The NYC traffic dataset describes information concerning the entrance and exits for all subway stations in New York City, including what subway lines are served by that station, the precise location of entrances, and other information such as staffing, vending and whether the station is compliant under the American Disabilities Act (ADA). 

The dataset was imported and the following data cleaning steps were taken: 

*  Specified column variable types when importing. 

*  Cleaned column names using `janitor::clean_names`

*  Retained the following variables: line, station name, station latitude/longitude, routes served, entry, vending, entrance type, and ADA compliance.

*  Recoded the `entry` variable from a character to a logical variable type using the `recode` function and `as.logical` function. 

*  Converted data in the `line` and `station_name` columns to lower case. 

**Dimensions**: The dataset contains `r nrow(NYC_traffic_data)` rows and `r ncol(NYC_traffic_data)` columns. 

**Is this data tidy?** The dataset is not yet fully tidy, as each separate route and corresponding subway line are separated out into separate columns. Instead, the routes and corresponding subway lines should be collapsed into two columns: route name and route number. This step will be completed in the section below. 

### Questions:

1) **How many distinct stations are there?**

To extract the number of distinct stations, created a subset of data removing duplicates based on both `station_name` and `line`. This dataset still maintains information for all other variables kept above. 
```{r extract distinct stations}
distinct_NYC_traffic_data = distinct(NYC_traffic_data, line, station_name, .keep_all = TRUE)
  
```

There are `r nrow(distinct_NYC_traffic_data)` distinct stations. 

2) **How many stations are ADA compliant?**

There are `r length(distinct_NYC_traffic_data$ada[distinct_NYC_traffic_data$ada == TRUE])` unique ADA compliant stations. 

3) **What proportion of station entrances / exits without vending allow entrance?**

Use filter to make a filtered dataset based on distinct stations without vending: 
```{r}
filter_distinct_NYC_traffic_data = filter(distinct_NYC_traffic_data, vending == "NO")

```

The proportion of station entrance/exits without vending allowing entrance is `r mean(filter_distinct_NYC_traffic_data$entry)`. 

## Reformat Route Number and Route Name Variables 
To finish making this data tidy, data is reformatted so that route number and route name are distinct variables. Route names equal to "NA" were removed, and data was sorted by line and station_name. 

```{r}
tidy_distinct_NYC_traffic_data = 
  gather(distinct_NYC_traffic_data, key = route_number, value = route_name, route1:route11) %>%
  filter(route_name != "NA") %>% 
  arrange(line, station_name)
```

### Questions: 
1. **How many distinct stations serve the A train?**
There are `r nrow(filter(tidy_distinct_NYC_traffic_data, route_name == "A"))` distinct stations serving A train. 

2. **Of the stations that serve the A train, how many are ADA compliant?**
There are `r nrow(filter(tidy_distinct_NYC_traffic_data, route_name == "A" & ada == TRUE))` ADA compliant stations of those which serve the A train. 

# Problem 2: Mr Trash Wheel Data

## Import and Clean Whole Dataset

```{r important trash wheel data}
trash_wheel_data = read_excel("data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", 
                              sheet = 1, 
                              range = cell_cols("A:N")) %>% 
    janitor::clean_names() %>% 
    filter(dumpster != "NA", month != "Grand Total") %>% 
    mutate(sports_balls = round(sports_balls, digits = 0)) %>% 
    mutate(sports_balls = as.integer(sports_balls))
    
```

The following steps were taken to clean the dataset:

*  omitted columns with notes
*  cleaned variable names using `janitor::clean_names()`
*  filtered out rows that do not include dumpster-specific data
*  rounded number of sports balls to nearest integer and converted into integer value. 

## Read and Clean Precipitation Data 2016 and 2017

Next, precipitation data from 2016 and 2017 was read and cleaned. 

```{r import and clean precip data 2016 and 2017}
precip_2017_data = read_excel("data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", 
                              sheet = 3, skip = 1) %>% 
      janitor::clean_names() %>% 
      filter(month != "NA", total != "NA") %>% 
      mutate(year = 2017) %>% 
      select(year, month, total)

                              
precip_2016_data = read_excel("data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", 
                              sheet = 4, skip = 1) %>% 
      janitor::clean_names() %>%
      filter(month != "NA", total != "NA") %>%
      mutate(year = 2016) %>% 
      select(year, month, total)

```

Next, the datasets from 2016 and 2017 were joined: 

```{r join precip 2016 and 2017 data}
precip_data_all = full_join(precip_2016_data, precip_2017_data)
# need to add the month conversion

```

## Description of Dataset

The Healthy Harbor Water Wheel data describes trash collected by a water wheel vessel in the Inner Harbor, Baltimore. The data has been split into two datasets: 

*  `trash_wheel_data`, which contains data on the amount of trash collected by each dumpster by specific trash type. Key variables include `dumpster`, `month`, `year`, `weight_tons` and `volume_cubic_yards` which provide important information on the dumpster of interest, when the data was collected and the trash weight and volume. This dataset has `r nrow(trash_wheel_data)` rows and `r ncol(trash_wheel_data)` columns. 

*  `precip_data_all` is a complete dataset containing the precipitation in inches from months in 2016 and 2017. `year` contains the year data was collected, `month` describes the month of collection, and `total` describes the total precipitation. The 2016 dataset contains precipitation data from `r length(precip_data_all$year[precip_data_all$year == 2016])` months and the 2017 dataset contains precipitation data from `r length(precip_data_all$year[precip_data_all$year == 2017])` months. 

The total precipitation in 2017 is: `r sum(precip_2017_data$total)`. 

The median number of sports balls in a dumpster in 2016 is:
```{r median sports balls in 2016, echo = FALSE}
trash_wheel_data_2016 = filter(trash_wheel_data, year == 2016) %>% 
    mutate(sports_balls = as.numeric(sports_balls))

    median(trash_wheel_data_2016$sports_balls)
```



