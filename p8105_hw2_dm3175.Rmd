---
title: "p8105_hw2_dm3175"
author: "Devon Morgan"
date: "9/26/2018"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(p8105.datasets)
library("dplyr")
library(readxl)
library(viridis)
```

# Problem 1: NYC Transit Data
Problem 1 will use NYC Transit Data which includes information on entrance and exits for all subway stations located in New York City. 

## Import and Clean Dataset
The dataset was first imported and cleaned: 

```{r import nyc transit data}
NYC_traffic_data = read_csv(file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
                            col_types = "cccddccccccccccccccccclclcccddcc") %>% 
  janitor::clean_names() %>% 
  select(line, station_name, station_latitude, station_longitude, 
       route1:route11, entry, vending, entrance_type, ada) %>% 
  mutate(entry = recode(entry, 'YES' = "TRUE", 'NO' = "FALSE")) %>% 
  mutate(entry = as.logical(entry),
          entrance_type = tolower(entrance_type),
          line = tolower(line),
          station_name = tolower(station_name))
```

## Description of Dataset
The NYC traffic dataset describes information concerning the entrance and exits for all subway stations in New York City, including what subway lines are served by that station, the precise location of entrances, and other information such as staffing, vending and whether the station is compliant under the American Disabilities Act (ADA). 

The dataset was imported and the following data cleaning steps were taken: 

*  Specified column variable types when importing. 

*  Cleaned column names using `janitor::clean_names`

*  Retained the following variables: line, station name, station latitude/longitude, routes served, entry, vending, entrance type, and ADA compliance.

*  Recoded the `entry` variable from a character to a logical variable type using the `recode` function and `as.logical` function. 

*  Converted data in the `line` and `station_name` columns to lower case. 

**Dimensions**: The dataset contains `r nrow(NYC_traffic_data)` rows and `r ncol(NYC_traffic_data)` columns. 

**Is this data tidy?** The dataset is not yet fully tidy, as each separate route and corresponding subway line are separated out into separate columns. Instead, the routes and corresponding subway lines should be collapsed into two columns: route name and route number. This step will be completed in the section below. 

### Questions:

1) **How many distinct stations are there?**

To extract the number of distinct stations, created a subset of data removing duplicates based on both `station_name` and `line`. This dataset still maintains information for all other variables kept above. 
```{r extract distinct stations}
distinct_NYC_traffic_data = distinct(NYC_traffic_data, line, station_name, .keep_all = TRUE)
  
```

There are `r nrow(distinct_NYC_traffic_data)` distinct stations. 

2) **How many stations are ADA compliant?**

There are `r length(distinct_NYC_traffic_data$ada[distinct_NYC_traffic_data$ada == TRUE])` unique ADA compliant stations. 

3) **What proportion of station entrances / exits without vending allow entrance?**

The proportion of station entrance/exits without vending allowing entrance is:
```{r}
filter(NYC_traffic_data, vending == "NO") %>% pull(entry) %>% mean()
```

## Reformat Route Number and Route Name Variables 
To finish making this data tidy, data is reformatted so that route number and route name are distinct variables. Route names equal to "NA" were removed, and data was sorted by line and station_name. 

```{r}
tidy_distinct_NYC_traffic_data = 
  gather(distinct_NYC_traffic_data, key = route_number, value = route_name, route1:route11) %>%
  filter(route_name != "NA") %>% 
  arrange(line, station_name)
```

### Questions: 
1. **How many distinct stations serve the A train?**
There are `r filter(tidy_distinct_NYC_traffic_data, route_name == "A") %>% nrow()` distinct stations serving A train.

2. **Of the stations that serve the A train, how many are ADA compliant?**
There are `r filter(tidy_distinct_NYC_traffic_data, route_name == "A" & ada == TRUE) %>% nrow()` ADA compliant stations of those which serve the A train. 

# Problem 2: Mr Trash Wheel Data

## Import and Clean Whole Dataset

```{r important trash wheel data}
trash_wheel_data = read_excel("data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", 
                              sheet = 1, 
                              range = cell_cols("A:N")) %>% 
    janitor::clean_names() %>% 
    filter(dumpster != "NA", month != "Grand Total") %>% 
    mutate(sports_balls = round(sports_balls, digits = 0)) %>% 
    mutate(sports_balls = as.integer(sports_balls))
    
```

The following steps were taken to clean the dataset:

*  omitted columns with notes
*  cleaned variable names using `janitor::clean_names()`
*  filtered out rows that do not include dumpster-specific data
*  rounded number of sports balls to nearest integer and converted into integer value. 

## Read and Clean Precipitation Data 2016 and 2017

Next, precipitation data from 2016 and 2017 was read and cleaned: 

```{r import and clean precip data 2016 and 2017}
precip_2017_data = read_excel("data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", 
                              sheet = 3, skip = 1) %>% 
      janitor::clean_names() %>%
      rename(precip_total = total) %>% 
      filter(month != "NA", precip_total != "NA") %>% 
      mutate(year = 2017) %>% 
      select(year, month, precip_total)

                              
precip_2016_data = read_excel("data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", 
                              sheet = 4, skip = 1) %>% 
      janitor::clean_names() %>%
      rename(precip_total = total) %>% 
      filter(month != "NA", precip_total != "NA") %>%
      mutate(year = 2016) %>% 
      select(year, month, precip_total)

```

The following data cleaning steps were taken: 

*  Clean variable names using `janitor::clean_names`
*  Renamed the total precipitation value to `precip_total`
*  Filtered out "NA" values for `month` and `precip_total`
*  Added `year` variable for year of data collection
*  Reordered columns

Next, the datasets from 2016 and 2017 were joined. The values for month in the original dataset were coded as integers. In this step, the integers were converted to month names using the built in `month.name` variable in R.  

```{r join precip 2016 and 2017 data}
precip_data_all = full_join(precip_2016_data, precip_2017_data) %>% 
    mutate(month = month.name[month])

```

## Description of Dataset

The Healthy Harbor Water Wheel data describes trash collected by a water wheel vessel in the Inner Harbor, Baltimore. The data has been split into two datasets: 

*  `trash_wheel_data`, which contains data on the amount of trash collected by each dumpster by specific trash type. Key variables include `dumpster`, `month`, `year`, `weight_tons` and `volume_cubic_yards` which provide important information on the dumpster of interest, when the data was collected and the trash weight and volume. The dataset also includes a breakdown of counts of garbage removed by type. This dataset has `r nrow(trash_wheel_data)` rows and `r ncol(trash_wheel_data)` columns. 

*  `precip_data_all` is a complete dataset containing the precipitation in inches from months in 2016 and 2017. `year` contains the year data was collected, `month` describes the month of collection, and `precip_total` describes the total precipitation. The 2016 dataset contains precipitation data from `r length(precip_data_all$year[precip_data_all$year == 2016])` months and the 2017 dataset contains precipitation data from `r length(precip_data_all$year[precip_data_all$year == 2017])` months. 

The **total precipitation in 2017** is: `r sum(precip_2017_data$precip_total)`. 

The **median number of sports balls** in a dumpster in 2016 is: `r filter(trash_wheel_data, year == 2016) %>% pull(sports_balls) %>% median()`. 

# Problem 3: BRFSS Data

The BRFSS dataset includes data from the Behavioral Risk Factors Surveillance System from 2002-2010. This dataset is located in the `p8105.datasets` package. 

## Import and Clean Dataset
Load and clean BRFSS data from `p9105.datasets` package: 

```{r load BRFSS Data}
brfss_data = p8105.datasets::brfss_smart2010 %>% 
    janitor::clean_names() %>%
    filter(topic == "Overall Health") %>% 
    select(year, 
           location_abbr = locationabbr, 
           location_desc = locationdesc,
           response,
           data_value) %>% 
    spread(key = response, value = data_value) %>% 
    janitor::clean_names() %>%
    mutate(proportion_excellent_very_good = 
             (excellent + very_good)/(excellent + fair + very_good + poor + good)) %>% 
    select(year, 
           location_abbr, 
           location_desc, 
           excellent, 
           very_good, 
           good, 
           fair, 
           poor,  
           proportion_excellent_very_good)
  
```

The following steps were taken to clean the dataset: 

*  Cleaned variable names using `janitor::clean_names`.

*  Verified variable types imported correctly.

*  Filtered data to only consider "Overall Health".

*  Selected to keep the following variables: `year`, `location_abbr` which includes an abbreviation for state, `location_desc` which includes a description of specific site, `response` which includes description of response for survey, and `data_value` which includes the numeric value of response. 

*  Strutured data so that values for Response (“Excellent” to “Poor”) are column names / variables which indicate the proportion of subjects with each response (which are values of Data_value in the original dataset) using `spread`.

*  Created variable for `proportion_excellent_very_good` which describes the proportion of responses that were “Excellent” or “Very Good”. 

*  Reordered columns using the `select` function. 

## Questions about Dataset

*  **How many unique locations are included in the dataset? Is every state represented? What state is observed the most?** 
There are `r distinct(brfss_data, location_desc, .keep_all = TRUE) %>% nrow()` unique locations included in the dataset. All `r distinct(brfss_data, location_abbr, .keep_all = TRUE) %>% nrow()` states are represented including Washington, DC. 

Next, the most frequently represented state was located by calculating the frequency of each state and then finding the state corresponding to the highest frequency. The **most frequently represented state was New Jersey**.  

```{r}
# Find frequency for each state and find max frequency associated with that state. 

count(brfss_data, location_abbr) %>%
  pull(n) %>% 
  max()

 # Filter by highest frequency value and find the corresponding state
count(brfss_data, location_abbr) %>%
  filter(n == 146) 
```

*  **In 2002, what is the median of the "Excellent" response value?**
In 2002, the median of the "Excellent" response value was `r filter(brfss_data, year == 2002) %>% pull(excellent) %>% median(na.rm = TRUE)`. 

*  **Make a histogram of "Excellent" response values in the year 2002?**

The following histogram presents the count of "Excellent" response values in 2002 for all states sampled. 

```{r histogram of 2002 excellent responses}
filter(brfss_data, year == 2002) %>% 
    ggplot(aes(x = excellent)) + 
      geom_histogram() +
      labs(
        title = "Histogram of Excellent Response Values in 2002",
        x = "Excellent Response Value",
        y = "Count",
        caption = "Data from BRFSS dataset"
        )

```

*  **Make a scatterplot showing the proportion of "Excellent" response values in New York County and Queens County (both in NY state) in each year from 2002 to 2010.**

The following scatterplot presents the proportion of "Excellent" response values in New York County and Queens County in each year from 2002 to 2010. 

```{r scatterplot of excellent in NY county and queens}
filter(brfss_data, location_desc == "NY - New York County" | location_desc == "NY - Queens County") %>%
  mutate(proportion_excellent = (excellent)/(excellent + fair + very_good + poor + good)) %>% 
  ggplot(aes(x = year, y = proportion_excellent)) + 
  geom_point(aes(color = location_desc), alpha = .5) + 
  labs(
    title = "Proportion of Excellent Response Values per Year from 2002 to 2010",
    x = "Year",
    y = "Proportion of Excellent Response Values Each Gear",
    caption = "Data from the BRFSS dataset"
  ) + 
  ggthemes::scale_color_wsj(name = "Location") +
  theme_bw() + 
  theme(legend.position = "bottom")

```



